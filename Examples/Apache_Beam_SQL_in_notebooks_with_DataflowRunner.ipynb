{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "394e1cd2",
      "metadata": {},
      "source": [
        "##### Copyright 2021 Google Inc.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\").\n",
        "\u003c!--\n",
        "    Licensed to the Apache Software Foundation (ASF) under one\n",
        "    or more contributor license agreements.  See the NOTICE file\n",
        "    distributed with this work for additional information\n",
        "    regarding copyright ownership.  The ASF licenses this file\n",
        "    to you under the Apache License, Version 2.0 (the\n",
        "    \"License\"); you may not use this file except in compliance\n",
        "    with the License.  You may obtain a copy of the License at\n",
        "\n",
        "      http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "    Unless required by applicable law or agreed to in writing,\n",
        "    software distributed under the License is distributed on an\n",
        "    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "    KIND, either express or implied.  See the License for the\n",
        "    specific language governing permissions and limitations\n",
        "    under the License.\n",
        "--\u003e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04f8b934-ed50-482e-bf36-fa65c766b990",
      "metadata": {
        "tags": []
      },
      "source": [
        "# Beam SQL in notebooks\n",
        "## Run with DataflowRunner\n",
        "\n",
        "This example demonstrates how to run Beam SQL using DataflowRunner. \n",
        "Please run `Apache_Beam_SQL_in_notebooks.ipynb` to learn Beam SQL basics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b4a6b21-cc5c-47f2-82d8-e4ec44d143de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# The notebook environment should have docker and jdk 1.8 installed.\n",
        "!docker image list\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b5d5c83-d14e-4787-a850-de14f4075f48",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optionally sets the logging level to reduce distraction.\n",
        "import logging\n",
        "\n",
        "logging.root.setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda16c42-341b-481c-b704-6d9d3c76d048",
      "metadata": {},
      "source": [
        "Let's install the `names` package to randomly generate some names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "564ade39-dbbf-4cf6-967e-5f853570319f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af1bb84a-be9e-4f3b-98fb-c7750e5b19d0",
      "metadata": {},
      "source": [
        "Import all modules needed for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec5c9b4-ddaa-4d2c-968c-a86c430cfdcd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import names\n",
        "import typing\n",
        "\n",
        "import apache_beam as beam\n",
        "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n",
        "from apache_beam.runners.interactive import interactive_beam as ib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8af4cd3-8ef3-4108-a76b-2e9006c0a935",
      "metadata": {},
      "source": [
        "Create a pipeline `p` with the `InteractiveRunner`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801f535b-0cfc-4e97-a092-0ff9142350f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "p = beam.Pipeline(InteractiveRunner())"
      ]
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": [
        "class Person(typing.NamedTuple):\n",
        "    id: int\n",
        "    name: str"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e80d164-93bb-4189-985d-8e0ccf4ee8e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# get a subset of full names\n",
        "persons_2 = (p \n",
        "             | beam.Create([Person(id=x, name=names.get_full_name()) for x in range(5, 15)]))\n",
        "ib.show(persons_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5a5649f-c046-4ab0-bb87-bd4c8e646a78",
      "metadata": {},
      "source": [
        "## Run Beam SQL on Dataflow via `beam_sql` magic\n",
        "\n",
        "Next you can execute the Beam SQL on Dataflow by specifying `-r DataflowRunner`.\n",
        "\n",
        "A form will be generated below for you to fill in minimum pipeline options needed. Some of the fields might have been auto-populated based on the context of this notebook environment.\n",
        "\n",
        "There are 2 buttons:\n",
        "- `Run on Dataflow` submits a Dataflow job from this notebook.\n",
        "- `Show Options` shows you the current pipeline options configured for the job to be submitted.\n",
        "\n",
        "**Important**: If you're using Beam built from source code, you need to execute the cell after next cell to set `sdk_location` before clicking the `RUN ON DATAFLOW` button generated by this cell.\n",
        "\n",
        "**Tips**: In the form generated by the `beam_sql` magic, use `gs://your-GCS-bucket` as the `GCS Bucket` and put `names` in the `Additional Packages`. The output PCollection will be automatically saved to `gs://your-GCS-bucket/staging/on_dataflow` file on Cloud Storage."
      ]
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": [
        "# you might need to update ipywidgets if the form cannot be shown\n",
        "# %pip install -U ipywidgets"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f4e40db",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%beam_sql -o on_dataflow -r DataflowRunner\n",
        "SELECT * FROM persons_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b561c6cf-2e8d-492b-ba82-42be42f1743c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment and execute if you're using Beam built from source code.\n",
        "# from apache_beam.options.pipeline_options import SetupOptions\n",
        "# options_on_dataflow.view_as(SetupOptions).sdk_location = '/dir/to/your/apache-beam-x.xx.x.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d57eef-86b0-42dc-830c-3513756cf8cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace your-GCS-bucket with the real input and execute once the dataflow job is done.\n",
        "!gsutil cat 'gs://your-GCS-bucket/staging/abc-00000-of-00001'"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "toc-autonumbering": false,
    "toc-showcode": true,
    "toc-showmarkdowntxt": false
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
